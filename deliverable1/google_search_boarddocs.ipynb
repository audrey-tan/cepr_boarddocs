{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook searches Google to get the boarddocs website of each school district. We iteratively work on the csv marked as \"working\" to get the schools that we didn't get to before because of errors.\n",
    "\n",
    "Input:\n",
    "- `kaggle_school_districts.csv`\n",
    "- `working_school_districts_with_boarddocs_scraped.csv`\n",
    "\n",
    "Output:\n",
    "- `working_school_districts_with_boarddocs_scraped.csv`\n",
    "- `school_districts_with_boarddocs_scraped.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API credentials\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "google_cse_id = os.getenv(\"GOOGLE_CSE_ID\")\n",
    "\n",
    "if not google_api_key or not google_cse_id:\n",
    "    raise ValueError(\"API Key or CSE ID not found. Ensure they are set in the environment.\")\n",
    "\n",
    "\n",
    "# Function to perform Google API search\n",
    "def google_search(query, user_id=0):\n",
    "    url = \"https://customsearch.googleapis.com/customsearch/v1\"\n",
    "    \n",
    "    params = {\n",
    "        \"key\": google_api_key,\n",
    "        \"cx\": google_cse_id,\n",
    "        \"q\": query,\n",
    "        \"num\": 1,  # Fetch only the top result\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        results = response.json()\n",
    "        if \"items\" in results:\n",
    "            return results[\"items\"][0][\"link\"]\n",
    "    except Exception as e:\n",
    "        # before printing the error, remove any secrets\n",
    "        error_string = str(e)\n",
    "        # error_string = error_string.replace(google_api_key, \"REDACTED_GOOGLE_API_KEY\")\n",
    "        # error_string = error_string.replace(google_cse_id, \"REDACTED_GOOGLE_CSE_KEY\")\n",
    "        print(f\"Error for query '{query}': {error_string}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file exists\n",
    "working_filename = \"working_school_districts_with_boarddocs_scraped.csv\"\n",
    "\n",
    "if not os.path.exists(working_filename):\n",
    "    # Load the school districts CSV\n",
    "    df = pd.read_csv(\"lea_boarddocs_queries.csv\")\n",
    "    # Add an empty column called 'url' to the dataframe\n",
    "    df['url'] = ''\n",
    "    df['url'] = df['url'].astype('str')\n",
    "    # Write the dataframe to a CSV file\n",
    "    df.to_csv(working_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the working copy\n",
    "df = pd.read_csv(working_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get them to be objects as dtype\n",
    "df = df.astype('object')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of all school boards: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the remaining ones\n",
    "remaining_df = df[df['url'].isna()]\n",
    "print(f\"Number of remaining school boards to scrape: {remaining_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with 10\n",
    "# remaining_df = remaining_df.sample(1900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the queries\n",
    "import time\n",
    "\n",
    "queries = remaining_df[\"LEA_NAME\"]\n",
    "\n",
    "# Perform Google search for each school district with tqdm progress bar\n",
    "results = []\n",
    "sleep_flag = True\n",
    "for query in tqdm(queries, desc=\"Searching Google\", unit=\"query\"):\n",
    "    # sleep will introduce the lag so that we hit right at the rate limit by Google\n",
    "    if sleep_flag:\n",
    "        # 60 seconds per 100 operations\n",
    "        # time.sleep(60/100)\n",
    "        # time.sleep(60/200)\n",
    "        # optimized to sleep for less by including computation time\n",
    "        # should be 25% faster\n",
    "        time.sleep(0.4)\n",
    "    results.append(google_search(query))\n",
    "\n",
    "# Add the results to the DataFrame\n",
    "remaining_df[\"url\"] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a sample of results\n",
    "remaining_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep the ones with non NA\n",
    "remaining_df = remaining_df[~remaining_df['url'].isna()]\n",
    "print(f\"Number of new non-NA results: {remaining_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows that are in remaining_df[\"school_district\"]\n",
    "df = df[~df[\"LEAID\"].isin(remaining_df[\"LEAID\"])]\n",
    "\n",
    "# Concatenate remaining_df to df\n",
    "df = pd.concat([df, remaining_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge remaining_df with df on 'school_district' and 'state' columns\n",
    "df.update(remaining_df.set_index('LEAID'), overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to the working CSV\n",
    "df.to_csv(working_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage done\n",
    "percentage_done = str(round((df[~df[\"url\"].isna()].shape[0] / df.shape[0])*100,2)) + '%'\n",
    "print(f\"Percentage of total school boards scrapped: {percentage_done}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cepr_schoolboard)",
   "language": "python",
   "name": "cepr_schoolboard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
