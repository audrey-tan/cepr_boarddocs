{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"accounts\"\n",
    "start_date = \"02/10/2000\" # MM/DD/YYYY\n",
    "end_date = \"02/10/2026\" # MM/DD/YYYY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop for all schools\n",
    "import csv\n",
    "\n",
    "with open(\"boardbook_schools.csv\", newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "\n",
    "    for row in reader:\n",
    "        school_name = row[\"School Name\"]\n",
    "        index = row[\"Index\"]\n",
    "        has_search = row[\"has_search_index\"]\n",
    "\n",
    "        print(f\"üîç Searching for: {school_name} (Index: {index})\")\n",
    "\n",
    "        if has_search == \"True\":\n",
    "            search_school(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get search result from BoardBook's search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "BASE_URL = \"https://meetings.boardbook.org\"\n",
    "\n",
    "def is_valid_date_format(date_str: str):\n",
    "    pattern = r\"^(0[1-9]|1[0-2])/([0][1-9]|[12][0-9]|3[01])/\\d{4}$\"\n",
    "    return re.match(pattern, date_str) is not None\n",
    "\n",
    "# Step 1: Search request\n",
    "\n",
    "def request_search(school_id):\n",
    "    if not is_valid_date_format(start_date):\n",
    "        print(f\"Invalid start date format: {start_date}. Expected MM/DD/YYYY.\")\n",
    "    elif not is_valid_date_format(end_date):\n",
    "        print(f\"Invalid end date format: {end_date}. Expected MM/DD/YYYY.\")\n",
    "    else:\n",
    "        search_url = f\"{BASE_URL}/Search/AjaxSearch/{school_id}\"\n",
    "        params = {\n",
    "            \"q\": keyword,\n",
    "            \"returnUrl\": \"\",\n",
    "            \"i\": [4, 8, 9],\n",
    "            \"from\": start_date,\n",
    "            \"to\": end_date,\n",
    "            # \"_\": \"1743820823754\"\n",
    "        }\n",
    "        response = requests.get(search_url, params=params)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the search results to download the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "import re\n",
    "\n",
    "def download_pdf(url, filename, school_id):\n",
    "    os.makedirs(\"downloads/\" + school_id, exist_ok=True)\n",
    "    file_path = os.path.join(\"downloads/\" + school_id, filename)\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Downloaded: {file_path}\")\n",
    "\n",
    "# Step 2: Parse results\n",
    "def parse_search(school_id):\n",
    "    for a in soup.select(\"a[href^='/Search/GoToResult/']\"):\n",
    "        href = a[\"href\"]\n",
    "        full_url = urljoin(BASE_URL, href)\n",
    "        index_type = href.split(\"Index=\")[-1].split(\"&\")[0]\n",
    "\n",
    "        if \"sparqmeetingsagendaitems\" in index_type:\n",
    "            print(f\"Agenda item: {full_url}\")\n",
    "            r = requests.get(full_url, allow_redirects=True)\n",
    "\n",
    "            if r.history and \"meeting=\" in r.url:\n",
    "                meeting_id = r.url.split(\"meeting=\")[-1]\n",
    "                agenda_url = f\"{BASE_URL}/Public/DownloadAgenda/{school_id}?meeting={meeting_id}\"\n",
    "                file_name = f\"Agenda_{meeting_id}.pdf\"\n",
    "                download_pdf(agenda_url, file_name, school_id)\n",
    "            else:\n",
    "                print(\"No meeting ID found.\")\n",
    "\n",
    "        elif \"sparqmeetingsdocuments\" in index_type:\n",
    "            print(f\"Document: {full_url}\")\n",
    "            r = requests.get(full_url)\n",
    "            html = r.text\n",
    "\n",
    "            # Use regex to find file ID\n",
    "            match = re.search(r'file=([a-f0-9\\-]{36})', html)\n",
    "            if match:\n",
    "                file_id = match.group(1)\n",
    "                direct_url = f\"{BASE_URL}/Documents/DownloadPDF/{file_id}?org={school_id}\"\n",
    "                file_name = f\"Doc_{file_id}.pdf\"\n",
    "                download_pdf(direct_url, file_name, school_id)\n",
    "            else:\n",
    "                print(\"No file ID found via regex.\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Skipping unrecognized index type: {index_type}\")\n",
    "\n",
    "def search_school(school_id):\n",
    "    request_search(school_id)\n",
    "    parse_search(school_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New CSV file with search index information created: premier_schools_with_search_index.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "\n",
    "BASE_URL = \"https://meetings.boardbook.org\"\n",
    "\n",
    "# Function to check if a school has a valid search index (i.e., not redirected)\n",
    "def check_search_index(school_index):\n",
    "    search_url = f\"{BASE_URL}/Search/AjaxSearch/{school_index}\"\n",
    "    try:\n",
    "        # Send the request and allow redirection\n",
    "        response = requests.get(search_url, allow_redirects=True)\n",
    "        \n",
    "        # If response.history is not empty, that means it was redirected\n",
    "        if response.history:\n",
    "            return False  # Redirected, no valid search index\n",
    "        else:\n",
    "            return True  # Not redirected, valid search index\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking search index for {school_index}: {e}\")\n",
    "        return False  # If there's any error, assume invalid search index\n",
    "\n",
    "# Read the original CSV file and write a new CSV with the 'has_search_index' column\n",
    "input_csv_file = \"boardbook_schools.csv\"\n",
    "output_csv_file = \"premier_schools_with_search_index.csv\"\n",
    "\n",
    "# Open the input CSV file and the output CSV file\n",
    "with open(input_csv_file, newline='') as infile, open(output_csv_file, mode='w', newline='') as outfile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    fieldnames = reader.fieldnames + [\"has_search_index\"]\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()  # Write the header to the new file\n",
    "    \n",
    "    # Loop through each row and check if the school has a valid search index\n",
    "    for row in reader:\n",
    "        school_name = row[\"School Name\"]\n",
    "        school_index = row[\"Index\"]\n",
    "        \n",
    "        # Check if the school has a valid search index\n",
    "        has_search_index = check_search_index(school_index)\n",
    "        \n",
    "        # Add the new field to the row\n",
    "        row[\"has_search_index\"] = \"True\" if has_search_index else \"False\"\n",
    "        \n",
    "        # Write the row to the output CSV\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"New CSV file with search index information created: {output_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "valid_search_index_count = 0\n",
    "\n",
    "# Open the CSV file to count the number of 'True' values in the 'has_search_index' column\n",
    "with open(\"premier_schools_with_search_index.csv\", newline='') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    \n",
    "    # Loop through each row and check if the school has a valid search index\n",
    "    for row in reader:\n",
    "        # The column for search index is 'has_search_index', not 'Index'\n",
    "        school_index = row[\"has_search_index\"]\n",
    "        \n",
    "        # Increment the counter if the value is 'True' (as a string)\n",
    "        if school_index == \"True\":\n",
    "            valid_search_index_count += 1\n",
    "\n",
    "# Print the count of schools with a valid search index\n",
    "print(f\"{valid_search_index_count} schools have a valid search index.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def get_true_schools(file_path):\n",
    "    true_schools = set()\n",
    "    with open(file_path, newline='') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            if row.get(\"has_search_index\") == \"True\":\n",
    "                school_name = row.get(\"School Name\", \"\").strip()\n",
    "                if school_name:\n",
    "                    true_schools.add(school_name)\n",
    "    return true_schools\n",
    "\n",
    "# Load schools with 'True' from both files\n",
    "true_schools_1 = get_true_schools(\"schools_with_search_index.csv\")\n",
    "true_schools_2 = get_true_schools(\"premier_schools_with_search_index.csv\")\n",
    "\n",
    "# Find intersection\n",
    "overlap = true_schools_1 & true_schools_2\n",
    "\n",
    "# Print results\n",
    "print(f\"{len(overlap)} schools have 'True' in both files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
